[
  {
    "objectID": "Prediction.html",
    "href": "Prediction.html",
    "title": "2  Predicting new values",
    "section": "",
    "text": "Our work on Charlotte’s Willow oaks and squirrel populations caught the attention of conservation groups in South Carolina. They’d like to try and apply our model for estimating tree heights in Charleston. So the question this time is: can our model, developed to estimate tree heights in Charlotte, be used to reliably estimate tree height in Charleston?\nWhat we are asking our model to do here is predict the heights of trees we have not measured. Our model, which is based on a a linear relationship to our predictor variables, can provide us with estimates of tree heights for any set of values for our predictor variables, so it could be used to do this.\nImmediately, though, questions should arise about how well our model is likely to perform, particularly since we are in a new place. Are there local conditions that might introduce systematic bias? For example, would differences in soil or climate conditions affect the growth of trees in Charleston to the extent that it would affect the relationship between crown base height, DBH, and tree height?\nA sensible thing to do in this case would be to test the model using some Willow oaks in Charleston where the predictor variable data has already been collected and the heights of the trees is known. Luckily, such a dataset exists in our tree inventory!\nFirst, we can subset our data to the appropriate city and species:\n\ntreeDataSC&lt;-read_csv(\"data/TS3_Raw_tree_data.csv\") %&gt;%\n  filter(City==\"Charleston, SC\") %&gt;%\n  filter(CommonName==\"Willow oak\")\n\nRows: 14487 Columns: 41\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Region, City, Source, Zone, Park/Street, SpCode, ScientificName, C...\ndbl (25): DbaseID, cell, Age, DBH (cm), TreeHt (m), CrnBase, CrnHt (m), Cdia...\nnum  (1): TreeID\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntreeDataSC\n\n# A tibble: 45 × 41\n   DbaseID Region City   Source TreeID Zone  `Park/Street` SpCode ScientificName\n     &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;  &lt;chr&gt;         \n 1   10638 GulfCo Charl… CHSMa…  16918 S9    Street        QUPH   Quercus phell…\n 2   10679 GulfCo Charl… CHSMa…  17680 Q9    Street        QUPH   Quercus phell…\n 3   10698 GulfCo Charl… CHSMa…  18055 R10   Street        QUPH   Quercus phell…\n 4   10705 GulfCo Charl… CHSMa…  18180 K7    Street        QUPH   Quercus phell…\n 5   10714 GulfCo Charl… CHSMa…  18445 O7    Street        QUPH   Quercus phell…\n 6   10779 GulfCo Charl… CHSMa…  19370 S10   Street        QUPH   Quercus phell…\n 7   10780 GulfCo Charl… CHSMa…  19371 S10   Street        QUPH   Quercus phell…\n 8   10844 GulfCo Charl… CHSMa…  20354 R10   Street        QUPH   Quercus phell…\n 9   10848 GulfCo Charl… CHSMa…  20431 Q9    Street        QUPH   Quercus phell…\n10   10849 GulfCo Charl… CHSMa…  20432 Q9    Street        QUPH   Quercus phell…\n# ℹ 35 more rows\n# ℹ 32 more variables: CommonName &lt;chr&gt;, TreeType &lt;chr&gt;, address &lt;chr&gt;,\n#   street &lt;chr&gt;, side &lt;chr&gt;, cell &lt;dbl&gt;, OnStreet &lt;chr&gt;, FromStreet &lt;chr&gt;,\n#   ToStreet &lt;chr&gt;, Age &lt;dbl&gt;, `DBH (cm)` &lt;dbl&gt;, `TreeHt (m)` &lt;dbl&gt;,\n#   CrnBase &lt;dbl&gt;, `CrnHt (m)` &lt;dbl&gt;, `CdiaPar (m)` &lt;dbl&gt;,\n#   `CDiaPerp (m)` &lt;dbl&gt;, `AvgCdia (m)` &lt;dbl&gt;, `Leaf (m2)` &lt;dbl&gt;,\n#   Setback &lt;dbl&gt;, TreeOr &lt;dbl&gt;, CarShade &lt;dbl&gt;, LandUse &lt;dbl&gt;, Shape &lt;dbl&gt;, …\n\n\nNext, we can use the predict function to generate some predicted tree heights for This function takes two arguments\n\nThe model from which we are deriving predictions.\nA dataframe that has columns with names that match the predictor variable names from our model.\n\n\nSCtest&lt;-predict(treeMod_dbh,treeDataSC)\n\nTo evaluate our predictions, we need three pieces of information:\n\nHeights from Willow Oaks in Charleston,\nThe heights predicted for those trees by our model\nThe differences between them (also termed the residuals)\n\n\nobsHt_m&lt;-treeDataSC$`TreeHt (m)`\nmodHt_m&lt;-as.vector(SCtest)\nresidual&lt;-obsHt_m-modHt_m\ntestData&lt;-tibble(obsHt_m,modHt_m,residual)\n\n\nggplot(testData,aes(x=modHt_m,y=residual)) +\n  geom_point() +\n  geom_hline(yintercept=0,color=\"red\",lty=2) +\n  labs(x=\"Modeled height (m)\",y=\"Observed height (m)\",title=\"Testing Willow Oak height model \\nin Charleston, SC\") +\n  theme_light()\n\n\n\n\n\n\n\n\nWe can also look at this using a histogram:\n\nggplot(testData,aes(x=residual)) +\n  geom_histogram() +\n  geom_vline(xintercept=0,color=\"red\",lty=2) +\n  labs(x=\"Predicted height error (m)\",title=\"Testing Willow Oak height model \\nin Charleston, SC\") +\n  theme_light() \n\n\n\n\n\n\n\n\nThis outcome suggests that our model, based on the relationship between tree attributes in Charlotte, is systematically underestimating the heights of trees in Charleston. It’s not clear why this might be the case; assuming the data on these variables was recorded in a consistent way between these two locations, there is likely some confounding process we are not accounting for.\nTo get more accurate estimates of tree heights, our friends in Charleston will likely want to develop their own model using local data. Luckily, based on our previous experience, we can walk them through that process!\n\n2.0.1 Going further\nThis really only scratches the surface when it comes to modeling with data. Linear models are very useful, but are limited in their applications because they depend on the residuals for the response (dependent) variable being normally distributed, and this is not always the case. The Generalized Linear Model can be accessed using the glm function, and allows you to specify a family of distributions other than normal in your assessment of the data.\nFor example, the “ropey” variable in the scat dataset is a binary variable, expressed as 0 or 1. If we wanted to perform a regression on this data, because it’s residuals are not distributed normally. For example, let’s say we want to know if there is a predictive relationship between mass and ropeyness.\n\nlibrary(modeldata)\nggplot(scat,aes(x=Length,y=ropey)) + \n  geom_point()\n\n\n\n\n\n\n\n\nWe can see that there appears to be some difference between ropey (1) and non-ropey (0) scat in terms of their length. We can use glm to model this using a binomial logistic distribution:\n\nscatGLM&lt;-glm(ropey~Length,data=scat,family=binomial)\nsummary(scatGLM)\n\n\nCall:\nglm(formula = ropey ~ Length, family = binomial, data = scat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -0.86206    0.58162  -1.482    0.138  \nLength       0.12169    0.06042   2.014    0.044 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 150.71  on 109  degrees of freedom\nResidual deviance: 146.37  on 108  degrees of freedom\nAIC: 150.37\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe coefficients output here are similar to those from linear modeling. The Null Deviance and Residual Deviance are measures of how well the response variable (here ropey) is predicted by ; higher numbers The AIC (Akeake Information Criterion) is a metric that can be used for model comparison; the lower the number, the more effective the model. For example, we might try the same analysis with a different predictor variable, like degree of taper:\n\nscatGLM&lt;-glm(ropey~TI,data=scat,family=binomial)\nsummary(scatGLM)\n\n\nCall:\nglm(formula = ropey ~ TI, family = binomial, data = scat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.5960     0.6163  -2.590 0.009607 ** \nTI            1.3738     0.4152   3.309 0.000937 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 125.02  on 92  degrees of freedom\nResidual deviance: 109.83  on 91  degrees of freedom\n  (17 observations deleted due to missingness)\nAIC: 113.83\n\nNumber of Fisher Scoring iterations: 5\n\n\nThe glm function provides a number of different families of model, such as “Poisson” for count data with integers, or “Gamma” for continuous data with a positive skew.\nIf you’re interested in looking into doing more complex modeling, there are a number of resources out there. Here are a couple to get you started:\n\nThere is an excellent section on regression in YaRrr! The Pirate’s Guide to R by Nathaniel Phillips, including a section on using the Generalized Linear Model.\nFor a treatment on non-linear regression techniques, the book Introductory Biostatistics with R has a couple of chapters focused on dealing with\nIf you’re interested in doing more complex modeling and integrating modeling within the tidyverse workflow, I highly recommend Tidy Modeling with R by Max Kuhn and Julia Silge. The functions take on a very different structure, but once mastered can be very powerful for modeling data.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Predicting new values</span>"
    ]
  },
  {
    "objectID": "BuildingModels.html",
    "href": "BuildingModels.html",
    "title": "1  Building models",
    "section": "",
    "text": "Let’s say that the city of Charlotte, NC wants to protect critical habitats in its urban forests. A recent study has shown that the endangered Carolina northern flying squirrel has a preference for Willow Oak trees above a height of 25 meters. The city parks department works with local volunteers to identify these trees; however, taking accurate height measurements can be difficult and time-consuming. They would like to find an easier way to estimate height, so they turn to you, the trusty data scientist, to try and answer this question.\nThe question is one of prediction: can we use the relationship between tree height and some other variable(s) in order to predict tree height.\nFirst, let’s get some tree data into R:\n\nlibrary(tidyverse)\n\ntreeDataNC&lt;-read_csv(\"data/TS3_Raw_tree_data.csv\") %&gt;%\n  filter(City==\"Charlotte, NC\") %&gt;%\n  filter(CommonName==\"Willow oak\")\n\ntreeDataNC\n\n# A tibble: 49 × 41\n   DbaseID Region City   Source TreeID Zone  `Park/Street` SpCode ScientificName\n     &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;  &lt;chr&gt;         \n 1   11435 Piedmt Charl… CLTMa…  10225 F6    Street        QUPH   Quercus phell…\n 2   11439 Piedmt Charl… CLTMa…  11053 F6    Street        QUPH   Quercus phell…\n 3   11447 Piedmt Charl… CLTMa…  12222 F6    Street        QUPH   Quercus phell…\n 4   11462 Piedmt Charl… CLTMa…  13521 F6    Street        QUPH   Quercus phell…\n 5   11469 Piedmt Charl… CLTMa…  14232 F6    Street        QUPH   Quercus phell…\n 6   11503 Piedmt Charl… CLTMa…  19141 F5    Street        QUPH   Quercus phell…\n 7   11514 Piedmt Charl… CLTMa…  20011 F5    Street        QUPH   Quercus phell…\n 8   11539 Piedmt Charl… CLTMa…  23048 F6    Street        QUPH   Quercus phell…\n 9   11543 Piedmt Charl… CLTMa…  23565 E8    Street        QUPH   Quercus phell…\n10   11570 Piedmt Charl… CLTMa…  27540 F8    Street        QUPH   Quercus phell…\n# ℹ 39 more rows\n# ℹ 32 more variables: CommonName &lt;chr&gt;, TreeType &lt;chr&gt;, address &lt;chr&gt;,\n#   street &lt;chr&gt;, side &lt;chr&gt;, cell &lt;dbl&gt;, OnStreet &lt;chr&gt;, FromStreet &lt;chr&gt;,\n#   ToStreet &lt;chr&gt;, Age &lt;dbl&gt;, `DBH (cm)` &lt;dbl&gt;, `TreeHt (m)` &lt;dbl&gt;,\n#   CrnBase &lt;dbl&gt;, `CrnHt (m)` &lt;dbl&gt;, `CdiaPar (m)` &lt;dbl&gt;,\n#   `CDiaPerp (m)` &lt;dbl&gt;, `AvgCdia (m)` &lt;dbl&gt;, `Leaf (m2)` &lt;dbl&gt;,\n#   Setback &lt;dbl&gt;, TreeOr &lt;dbl&gt;, CarShade &lt;dbl&gt;, LandUse &lt;dbl&gt;, Shape &lt;dbl&gt;, …\n\n\nLet’s start with crown base height (CrnBase in the data): this is the average distance from the ground to the bottom of the tree’s crown:\n\n\n\nFerraz et al. 2009 The Role of Lidar Systems in Fuel Mapping\n\n\nWhat we’d like to know is whether a linear relationship exists between crown base height and tree height. By linear, we mean that an increase of some increment in one variable (crown base height) will result in an increase in the variable of interest (tree height). Let’s see what the relationship between our variables looks like visually:\n\nggplot(treeDataNC,aes(x=CrnBase,y=`TreeHt (m)`)) +\n  geom_point() +\n  labs(x=\"Crown Base (m)\",y=\"Tree Height (m)\") +\n  theme_light()\n\n\n\n\n\n\n\n\nNotice CrnBase is not surrounded by backticks, while TreeHt (m) has them. Remember that the reason is that CrnBase doesn’t have any non-standard characters like whitespace or parentheses, so the read_csv function didn’t add them, and they aren’t needed to refer to the variable in the aesthetic mapping.\nOK, so what do we see here? Well, there does seem to be an increase, but it isn’t very strong. We can assess this strength by doing a correlation test:\n\n#check pearson\ncor.test(treeDataNC$CrnBase,treeDataNC$`TreeHt (m)`,method=\"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  treeDataNC$CrnBase and treeDataNC$`TreeHt (m)`\nt = 5.3424, df = 47, p-value = 2.62e-06\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.4031591 0.7638432\nsample estimates:\n      cor \n0.6146721 \n\n\nThe cor value is 0.61, which suggests a positive relationship, but it isn’t especially strong. The p-value is very low, though, so this indicates we can reject the idea there isn’t a relationship. Of course, we didn’t check to see whether the data are normally distributed. We can use shapiro.test to do that:\n\n#check normality\nshapiro.test(treeDataNC$`TreeHt (m)`)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treeDataNC$`TreeHt (m)`\nW = 0.96854, p-value = 0.2117\n\nshapiro.test(treeDataNC$CrnBase)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treeDataNC$CrnBase\nW = 0.84429, p-value = 1.293e-05\n\n\nRemembering back to Week 6, a p-value greater than our cut-off threshold (0.05) tells us that we can’t reject the null hypothesis that the data are normally distributed. This is true for tree height, but not so for the crown base height. Therefore, we should probably run our correlation test again, but this time using the Spearman method:\n\n#check spearman\ncor.test(treeDataNC$CrnBase,treeDataNC$`TreeHt (m)`,method=\"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  treeDataNC$CrnBase and treeDataNC$`TreeHt (m)`\nS = 6156.7, p-value = 5.37e-08\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6858807 \n\n\nThe result is pretty similar: we can reject the idea that there is no relationship, and the data indicate a positive relationship. The rho value is a little improved, but not by a lot.\n\n1.0.1 Building a model: Single predictor regression\nGiven the existence of a relationship, we could ask: how well can we predict tree height from crown base height? A linear model can help us to estimate this. If you think back to our scatter plot, what a linear model does is draw a straight line through the data that minimizes the distance to all of the points.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIf we find that the line fits the data well, which would be indicated by how closely the data points fall along it, then we can use the line to provide us with predictions about data we have not observed. For example, looking at the plot above, the linear model would predict that a tree with a crown base height of 10 meters would have a total height of about 31 meters. Of course, the value of this prediction depends on how well the model fits the data.\nTo create our model, we’ll use the lm, or linear model, function:\n\ntreeModel&lt;-lm(`TreeHt (m)`~ CrnBase,data=treeDataNC)\n\nWhat have we done here? What this code does is asks R to conduct a linear regression on these two variables and save it as a linear model object called treeModel. At a minimum, lm needs an argument that comes in the form of a formula:\ny~x\nWhere y is the response variable (tree height) and x is a predictor (crown base height). If we just want to use column names like we have here, we also have to supply a data argument, which in this case is the treeDataNC tibble. We could get the same result without this argument by referring to the columns using the $ operator:\n\ntreeMod_cb&lt;-lm(treeDataNC$`TreeHt (m)`~ treeDataNC$CrnBase)\n\nSo now our model is stored as treeMod_cb. We can get a quick look at the results by using the summary function:\n\nsummary(treeMod_cb)\n\n\nCall:\nlm(formula = treeDataNC$`TreeHt (m)` ~ treeDataNC$CrnBase)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.7496  -4.3383   0.9595   5.5553  11.1581 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         12.8348     1.7161   7.479 1.54e-09 ***\ntreeDataNC$CrnBase   1.8014     0.3372   5.342 2.62e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.591 on 47 degrees of freedom\nMultiple R-squared:  0.3778,    Adjusted R-squared:  0.3646 \nF-statistic: 28.54 on 1 and 47 DF,  p-value: 2.62e-06\n\n\nThere’s a few different pieces of information here, let’s go through some of the most relevant:\n\nResiduals: Residuals are how far the real data deviate from the line produced by the model. These are expressed here as an interquartile range for all the residuals.\nCoefficients: These are indicating the relative increments that the response variable changes in response to the predictors. In particular, it gives the estimate for the intercept and slope of the line; the standard error between our estimate and the actual mean of the data; a statistc t indicating how far this is error is from what we would expect if no linear relationship were present; and the Pr(&gt;t) gives the probability of obtaining t or greater from unrelated data by chance.\nResidual standard error This is the average amount that the response will deviate from the regression line. We can expect any predictions we make to be over or under a real value by about this much.\nR-squared (R2): These are measures of the proportion of variance in the response (dependent) variable accounted for by the model. A value of 1 would indicate a perfect match between predictor and response.\n\nMultiple R-squared is the raw R-squared; for instances where more than one predictor is used (see below), the R-squared will always increase no matter what.\nAdjusted R-squared adjusts for the number of predictors, giving a more balanced\n\n\nRemembering back to our lesson on hypothesis testing, the presence of a p-value lower than 0.05 suggests our model would be unlikely to occur by chance. An adjusted R-squared value of 0.36 is OK for a fit, but we may be able to do better. Let’s see if we can get a better match with diameter at breast height, or DBH:\n\nggplot(treeDataNC,aes(x=`DBH (cm)`,y=`TreeHt (m)`)) +\n  geom_point() +\n  geom_smooth(method=\"lm\",se=FALSE) +\n  labs(x=\"Diameter at Breast Height (cm)\",y=\"Tree Height (m)\") +\n  theme_light()\n\n\n\n\n\n\n\n\nHere you might notice is that we added an argument, method=\"lm\", to the geom_smooth function. This is saying that, , we want to use a linear model. This lets ggplot create a line from a linear model rather than use the default loess smoother. We also included the argument se=false, which removes the error ribbon around the line. This allows us to see the model as it would exist from the formula we used above.\nFrom this plot, it looks like there is a pretty good relationship between these two variables. However, we still want to assess the data using a correlation:\n\n#check normality\nshapiro.test(treeDataNC$`TreeHt (m)`)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treeDataNC$`TreeHt (m)`\nW = 0.96854, p-value = 0.2117\n\nshapiro.test(treeDataNC$`DBH (cm)`)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treeDataNC$`DBH (cm)`\nW = 0.9492, p-value = 0.03429\n\n#check spearman\ncor.test(treeDataNC$`DBH (cm)`,treeDataNC$`TreeHt (m)`,method=\"spearman\")\n\nWarning in cor.test.default(treeDataNC$`DBH (cm)`, treeDataNC$`TreeHt (m)`, :\nCannot compute exact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  treeDataNC$`DBH (cm)` and treeDataNC$`TreeHt (m)`\nS = 2571.2, p-value = 5.943e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n     rho \n0.868814 \n\n\nThe Spearman test says we can’t rule out a relationship (no surprise), and there is a stronger positive relationship than what we saw before (again, not surprising).\nNow let’s see how this performs as a model:\n\ntreeMod_dbh&lt;-lm(`TreeHt (m)`~`DBH (cm)`,data=treeDataNC)\nsummary(treeMod_dbh)\n\n\nCall:\nlm(formula = `TreeHt (m)` ~ `DBH (cm)`, data = treeDataNC)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.0051 -2.0312 -0.0645  2.0496 13.3311 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.24141    1.20525   6.838 1.44e-08 ***\n`DBH (cm)`   0.19576    0.01667  11.740 1.41e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.214 on 47 degrees of freedom\nMultiple R-squared:  0.7457,    Adjusted R-squared:  0.7403 \nF-statistic: 137.8 on 1 and 47 DF,  p-value: 1.411e-15\n\n\nThis gives us an improved R-squared, suggesting that more of the variability in this dataset is explained by the model. So if we’re looking for an easily-obtained metric that can be used to predict tree height in Charlotte, it seems like DBH is a good candidate.\nBut what if, rather than use one predictor or the other, we decided we wanted to use both crown base height and DBH? The lm function can accommodate this by using the + symbol in the formula, like so:\n\ntreeMod_dbhcb&lt;-lm(`TreeHt (m)`~ CrnBase + `DBH (cm)`,data=treeDataNC)\n\nWhat this means is that, we are now looking at the relationship between a change in crown base height as well as DBH and the heights of the trees. If we take a look at the results:\n\nsummary(treeMod_dbhcb)\n\n\nCall:\nlm(formula = `TreeHt (m)` ~ CrnBase + `DBH (cm)`, data = treeDataNC)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.6417 -2.7392  0.5231  2.5024  8.8383 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.31802    1.11825   5.650 9.66e-07 ***\nCrnBase      0.88047    0.20309   4.335 7.85e-05 ***\n`DBH (cm)`   0.16665    0.01571  10.608 6.02e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.589 on 46 degrees of freedom\nMultiple R-squared:  0.8195,    Adjusted R-squared:  0.8116 \nF-statistic: 104.4 on 2 and 46 DF,  p-value: &lt; 2.2e-16\n\n\nWe can see we improved our fit somewhat, increasing the adjusted R2 from 0.74 to 0.81. Our new model using both crown base height and DBH does a better job of predicting tree heights.\nBut now we need to ask ourselves a very important question: is this improvement in the fit of the model worth it? Remember that the model’s goal is to be able to make statements about tree heights in Charlotte for the purpose of conservation. If we need the data quickly, we may reason that training volunteers to record two metrics is more cumbersome than just one, and so a model that explains 74% of the variance is will do the job well enough. But if we wanted to use model outcomes for something else, like ordering fungicides for treating tree ailments where dosage is based on tree height, then maybe getting the model up to 81% is worthwhile. This is not something any R output can tell us: it’s up to us to decide when a model is useful for our purposes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Building models</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Usefully Wrong: Models in R",
    "section": "",
    "text": "Introduction\nA model is something that represents an aspect of the real world by way of an analogy. A model train, for example, can represent aspects of a real locomotive like wheels and car couplings through miniature replicas. Mathematical models like the Lotka-Volterra equations can represent the dynamics of predator and prey species through the the interactions of population growth and energy. Computer simulations are a class of models that can be used to represent all kinds of phenomena, from galaxies to climate systems to potatoes.\nAll models share an important quality: they are all imperfect representations of the real phenomenon. However, despite their imperfections, they are often used to help us better understand the world around us. There is famous quote often attributed to the statistician George Box that sums up this idea:\n“All models are wrong, but some models are useful.”\nOne of the key This lab will deal with how to use linear models for predicting relationships between variables.",
    "crumbs": [
      "Introduction"
    ]
  }
]